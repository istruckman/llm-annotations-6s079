{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "This notebook computes exact entity F1, Recall, and Precision scores against the Human-Labeled entities, which we consider to be ground truth."
      ],
      "metadata": {
        "id": "95fL51WA6WvB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAcY_Hnk4TUT"
      },
      "source": [
        "# Env Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSO5XIh6r7V_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import csv\n",
        "import math\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Xe2KgrsPH_",
        "outputId": "bded90a3-1680-44b1-bd9d-27e0b7f675ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/'6.8611 Research Project'/'Colab Notebooks'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "127RPKwZsQ15",
        "outputId": "67aff546-d4d3-43aa-eb64-636e06bc61b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/6.8611 Research Project/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70AoigM1u6Ct"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the datasets into dataframes\n",
        "def load_tsv_dataset(file_path):\n",
        "  \"\"\"\n",
        "  Loads a tsv dataset. Renames thne columns to 'token' and 'label'.\n",
        "  Note that renaming the columns will overwrite the first row of the dataframe\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(file_path, delimiter='\\t', header=None, engine='python')\n",
        "  df.columns = ['token', 'label']\n",
        "  return df\n",
        "\n",
        "def load_csv_dataset(file_path):\n",
        "  \"\"\"\n",
        "  Loads a csv dataset. Renames thne columns to 'token' and 'label'.\n",
        "  Note that renaming the columns will overwrite the first row of the dataframe\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(file_path, delimiter=',', header=None, engine='python')\n",
        "  df.columns = ['token', 'label']\n",
        "  return df"
      ],
      "metadata": {
        "id": "QoH_G4dLsXCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust dataset_name, num_shots, file_name_end\n",
        "dataset_name = \"NCBI-disease\"\n",
        "num_shots = \"few_shot\"\n",
        "file_name_end = \"-devel.csv\"\n",
        "\n",
        "all_tokens = load_tsv_dataset(\"llm-annotations/datasets/\"+dataset_name+\"/devel.tsv\")['token'].tolist()\n",
        "all_labels = load_tsv_dataset(\"llm-annotations/datasets/\"+dataset_name+\"/devel.tsv\")['label'].tolist()\n",
        "llm_devel_tokens = load_csv_dataset(\"devel_gpt_generated_datasets/\"+num_shots+\"/\"+dataset_name+file_name_end)['token'].tolist()\n",
        "llm_devel_labels = load_csv_dataset(\"devel_gpt_generated_datasets/\"+num_shots+\"/\"+dataset_name+file_name_end)['label'].tolist()"
      ],
      "metadata": {
        "id": "ToLiochbsnXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load_<file_type>_dataset's dataframe reads null as nan, so we convert nan back to null\n",
        "for i in range(len(all_tokens)):\n",
        "    token = all_tokens[i]\n",
        "    if isinstance(token,float) and str(token)==\"nan\":\n",
        "        all_tokens[i] = \"null\"\n",
        "\n",
        "for i in range(len(llm_devel_tokens)):\n",
        "    token = llm_devel_tokens[i]\n",
        "    if isinstance(token,float) and str(token)==\"nan\":\n",
        "        llm_devel_tokens[i] = \"null\"\n",
        "\n",
        "for i in range(len(llm_devel_labels)):\n",
        "  if isinstance(llm_devel_labels[i], float):\n",
        "    # no label next to tokens \"Example\", \"Text: \" for JNLPBA one_shot\n",
        "    llm_devel_labels[i] = \"O\"\n",
        "  else:\n",
        "    llm_devel_labels[i] = llm_devel_labels[i].split(\"-\")[0]"
      ],
      "metadata": {
        "id": "PnVQ-nhEsn5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset: \"+dataset_name)\n",
        "print(\"# shots: \"+num_shots)"
      ],
      "metadata": {
        "id": "rmIMoLEfsufp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64340c1c-1d03-4503-b85a-6fa2316fb100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: NCBI-disease\n",
            "# shots: few_shot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Entities\n",
        "An entity is a sequence of tokens starting with a token labeled as “B” and ends at the last consecutive token labeled as “I” (the token after this token is either labeled as “O” or the last token labeled “I” is the last token in the dataset). For intrinsic evaluation, we filtered for all the unique entities in the human-annotated and LLM-generated datasets such that later on if we find an entity in LLM-generated dataset that's not in human-annotated dataset, we can skip over that entity and know that it can't be correct due to a named entity being correct only if it is an exact match of the corresponding entity in the original human-annotated file."
      ],
      "metadata": {
        "id": "5fFXo9bV5LZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_orig_entities = set()\n",
        "i = 0\n",
        "\n",
        "while i<len(all_tokens):\n",
        "    current_entity = \"\"\n",
        "    if (all_labels[i]==\"B\"):\n",
        "        current_entity+=all_tokens[i]\n",
        "        i+=1\n",
        "        while (all_labels[i] == \"I\"):\n",
        "            current_entity+=\" \" + all_tokens[i]\n",
        "            i+=1\n",
        "        all_orig_entities.add(current_entity)\n",
        "        current_entity = \"\"\n",
        "    else:\n",
        "        i+=1"
      ],
      "metadata": {
        "id": "gWX-F-lGswZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all unique entities in LLM-generated dataset\n",
        "all_llm_entities = set()\n",
        "i = 0\n",
        "while i<len(llm_devel_tokens):\n",
        "    current_entity = \"\"\n",
        "    if (llm_devel_labels[i]==\"B\"):\n",
        "        entity_first_token_index = i\n",
        "        current_entity+=llm_devel_tokens[i]\n",
        "        i+=1\n",
        "        while (llm_devel_labels[i] == \"I\"):\n",
        "            current_entity+=\" \" + llm_devel_tokens[i]\n",
        "            i+=1\n",
        "        all_llm_entities.add(current_entity)\n",
        "        current_entity = \"\"\n",
        "    else:\n",
        "        i+=1"
      ],
      "metadata": {
        "id": "xIdsNVxjs343"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array_orig_entities = []\n",
        "i = 0\n",
        "while i<len(all_tokens):\n",
        "    current_entity = \"\"\n",
        "    if (all_labels[i]==\"B\"):\n",
        "        current_entity+=all_tokens[i]\n",
        "        entity_start_i = i\n",
        "        i+=1\n",
        "        while (all_labels[i] == \"I\"):\n",
        "            current_entity+=\" \" + all_tokens[i]\n",
        "            i+=1\n",
        "        before_context = []\n",
        "        context_start_i = entity_start_i\n",
        "        while (context_start_i>0 and len(before_context)<5):\n",
        "            before_context_token = all_tokens[context_start_i-1]\n",
        "            if (context_start_i-1!=0):\n",
        "                before_context_token = \" \"+before_context_token\n",
        "            elif (context_start_i-1!=len(all_tokens)-1):\n",
        "                before_context_token += \" \"\n",
        "            before_context.append(before_context_token)\n",
        "            context_start_i -=1\n",
        "        before_context = before_context[::-1]\n",
        "\n",
        "        after_context_i = i\n",
        "        after_context = []\n",
        "        while (after_context_i<len(all_tokens) and len(after_context)<5):\n",
        "            after_context_token = all_tokens[after_context_i]\n",
        "            if (after_context_i!=0):\n",
        "                after_context_token = \" \"+after_context_token\n",
        "            elif (after_context_i!=len(all_tokens)-1):\n",
        "                after_context_token += \" \"\n",
        "            after_context.append(after_context_token)\n",
        "            after_context_i+=1\n",
        "        array_orig_entities.append((current_entity, before_context, after_context,entity_start_i))\n",
        "\n",
        "        current_entity = \"\"\n",
        "    else:\n",
        "        i+=1"
      ],
      "metadata": {
        "id": "srlrJEustCjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array_llm_entities = []\n",
        "i = 0\n",
        "while i<len(llm_devel_tokens):\n",
        "    current_entity = \"\"\n",
        "    if (llm_devel_labels[i]==\"B\"):\n",
        "        entity_first_token_index = i\n",
        "        current_entity+=llm_devel_tokens[i]\n",
        "        entity_start_i = i\n",
        "        i+=1\n",
        "        while (llm_devel_labels[i] == \"I\"):\n",
        "            current_entity+=\" \" + llm_devel_tokens[i]\n",
        "            i+=1\n",
        "        if (current_entity in all_orig_entities):\n",
        "            before_context = []\n",
        "            while (entity_start_i>=0 and len(before_context)<5):\n",
        "                before_context.append(llm_devel_tokens[entity_start_i-1])\n",
        "                entity_start_i -=1\n",
        "            before_context = before_context[::-1]\n",
        "\n",
        "            after_context_i = i\n",
        "            after_context = []\n",
        "            while (after_context_i<len(llm_devel_tokens) and len(after_context)<5):\n",
        "                after_context.append(llm_devel_tokens[after_context_i])\n",
        "                after_context_i+=1\n",
        "            array_llm_entities.append((current_entity, before_context, after_context))\n",
        "\n",
        "        current_entity = \"\"\n",
        "    else:\n",
        "        i+=1"
      ],
      "metadata": {
        "id": "HYsreDKdtQnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Label Accuracy\n",
        "\n",
        "Keep track of which entity in array of entities from the LLM-generated dataset that we're at with an index counter variable llm_entity_check_index.\n",
        "Iterate over each entity in an array of entities from the human-annotated dataset.\n",
        "  - If the entity from human-annotated dataset is in set of all unique entities in LLM-generated dataset, compare that entity's before_context (array containing up to 5 tokens that were in front of this entity in human-annotated dataset) and after_context (array containing up to 5 tokens that were in front of this entity in human-annotated dataset) with the before_context and after_context of the entity in LLM-generated dataset[llm_entity_check_index:] if the entity in LLM-generated dataset has the same value. The two entities' are considered to be at the same position with sufficiently similar context if at least 3 of the 5 tokens in before_context and 3 of the 5 tokens in after_context have the same value and are in the same relative order. This estimates that there are 1-2 hallucinated/merged/different punctuation tokens in the LLM-generated dataset for every 5 tokens preceding and following a named entity.\n",
        "  - After matching an entity in human-annotated dataset with a corresponding entity in LLM-generated dataset, we increment llm_entity_check_index to prevent future entities in the human-annotated dataset with the same context from automatically being matched to an entity in LLM-generated dataset that already corresponds to"
      ],
      "metadata": {
        "id": "hAPhkSpA5XVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_entity_check_index = 0\n",
        "print(len(all_llm_entities))\n",
        "num_correct = 0\n",
        "for entity_context in array_orig_entities:\n",
        "    entity, before_context, after_context, entity_start_i = entity_context\n",
        "    if entity in all_llm_entities:\n",
        "        for i in range(llm_entity_check_index,len(array_llm_entities)):\n",
        "            llm_entity, llm_before_context,llm_after_context = array_llm_entities[i]\n",
        "            if (llm_entity == entity):\n",
        "                llm_before_context_string = ' '.join(llm_before_context)\n",
        "                llm_after_context_string = ' '.join(llm_after_context)\n",
        "                num_before_context_match = 0\n",
        "                num_after_context_match = 0\n",
        "\n",
        "                last_before_context_i = 0\n",
        "                for context_token in before_context:\n",
        "                    token_i = llm_before_context_string[last_before_context_i:].find(context_token)\n",
        "                    if (token_i!=-1):\n",
        "                        num_before_context_match+=1\n",
        "                        last_before_context_i = token_i\n",
        "\n",
        "                last_after_context_i = 0\n",
        "                for context_token in after_context:\n",
        "                    token_i = llm_after_context_string[last_after_context_i:].find(context_token)\n",
        "                    if (token_i!=-1):\n",
        "                        num_after_context_match+=1\n",
        "                        last_after_context_i = token_i\n",
        "                if (num_before_context_match>=3) and (num_after_context_match>=3):\n",
        "                  num_correct+=1\n",
        "                  llm_entity_check_index=i+1\n",
        "                  break\n",
        "print(\"# tokens in original devel dataset: \"+str(len(array_orig_entities)))\n",
        "print(\"# tokens in LLM-generated dataset: \"+str(len(array_llm_entities)))\n",
        "print(\"correct: \"+str(num_correct))\n",
        "print(\"precision: \"+str(num_correct/len(array_orig_entities)))"
      ],
      "metadata": {
        "id": "7iTmS5F-tZMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c1825e-ac9b-4ba5-bb48-5a093a95cda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "596\n",
            "# tokens in original devel dataset: 787\n",
            "# tokens in LLM-generated dataset: 395\n",
            "correct: 256\n",
            "precision: 0.3252858958068615\n"
          ]
        }
      ]
    }
  ]
}